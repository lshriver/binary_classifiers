{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspaces/quantum/')\n",
    "from colors import Bcolors as bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Load the training data\n",
    "with open('../data/split-data/train.npy', 'rb') as f:\n",
    "    train_input = np.load(f)\n",
    "    train_labels = np.load(f)\n",
    "\n",
    "# Load the testing data\n",
    "with open('../data/split-data/test.npy', 'rb') as f:\n",
    "    test_input = np.load(f)\n",
    "    test_labels = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classification runner\n",
    "def run(f_classify, x):\n",
    "    return list(map(f_classify, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classification evaluator\n",
    "def evaluate(predictions, actual) -> str:\n",
    "    correct = list(filter(\n",
    "        lambda item: item[0] == item[1],\n",
    "        list(zip(predictions, actual))\n",
    "    ))\n",
    "    \n",
    "    return '{} correct predictions out of {}. Accuracy {:.0f} %' \\\n",
    "        .format(len(correct), len(actual), 100*len(correct)/len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def specificity(matrix):\n",
    "    return matrix[0][0]/(matrix[0][0]+matrix[0][1]) if (matrix[0][0]+matrix[0][1] > 0) else 0\n",
    "\n",
    "def npv(matrix):\n",
    "    return matrix[0][0]/(matrix[0][0]+matrix[1][0]) if (matrix[0][0]+matrix[1][0] > 0) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_scores(train_labels, predictions, cm):  \n",
    "    print(evaluate(predictions, train_labels))\n",
    "    print()\n",
    "    print('The precision score is {:.2f}'\n",
    "        .format(precision_score(train_labels, predictions)))\n",
    "    print('The recall score is {:.2f}'\n",
    "        .format(recall_score(train_labels, predictions)))\n",
    "    print('The specificity score is {:.2f}'\n",
    "        .format(specificity(cm)))\n",
    "    print('The npv score is {:.2f}'\n",
    "       .format(npv(cm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ˜ˆ Unmaksing the Hypocrite Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for the hypocrite classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypocrite(passenger, weight):\n",
    "    return round(min(1,max(0,weight*0.5+random.uniform(0, 1))))\n",
    "\n",
    "hypocrite_predictions = run(lambda passenger: hypocrite(passenger, -0.5), train_input)\n",
    "hypocrite_cm = confusion_matrix(train_labels, hypocrite_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜ˆ \u001b[95mHypocrite classifier:\u001b[0m\n",
      "369 correct predictions out of 711. Accuracy 52 %\n",
      "\n",
      "The precision score is 0.34\n",
      "The recall score is 0.26\n",
      "The specificity score is 0.69\n",
      "The npv score is 0.59\n"
     ]
    }
   ],
   "source": [
    "print(f'ðŸ˜ˆ {bc.HEADER}Hypocrite classifier:{bc.ENDC}')\n",
    "print_classifier_scores(train_labels, hypocrite_predictions, hypocrite_cm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
